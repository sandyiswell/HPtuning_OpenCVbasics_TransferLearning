{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XsRxk8cyGIlm"
   },
   "outputs": [],
   "source": [
    "\"\"\"In this notebook we will learn how hyperparameter (HP) tuning is done on neural networks.\n",
    "Initially we will do HP tuning using simple for loop methods.\n",
    "In later notebooks we will use improved methods for tuning.\"\"\"\n",
    "\n",
    "# We will use MNIST handwritten dataset in this notebook.\n",
    "\n",
    "# Import necessary packages.\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGi2PNaIGJ4z",
    "outputId": "908cd1cc-1733-4dc0-caea-e2cc9093b50a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST data loaded\n"
     ]
    }
   ],
   "source": [
    "# Load mnist dataset from keras.\n",
    "# Ref: https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "print(\"MNIST data loaded\")\n",
    "points = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "XbF6IZcKvFez",
    "outputId": "8517aa94-a106-4d2f-e487-8b9815411b20"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# how these images look like in matplotlib?\n",
    "# Taking and viewing 12 th image from the dataset.\n",
    "plt.imshow(mnist.load_data()[0][0][12])   #, cmap='binary') # these are grayscale images therefore set colour map to binary.\n",
    "plt.xlabel(mnist.load_data()[0][1][12])   # printing the class label of the image.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRK2CdX5GJ8W"
   },
   "outputs": [],
   "source": [
    "def tune_mnist(num_train_imgs, num_hidden_units, dropout, learning_rate,momentum,epochs, batch_size):\n",
    "    \"\"\"For tuning purpose we are taking six HPs into consideration: \n",
    "    num_hidden_units, dropout, learning_rate,momentum,epochs and batch_size.\n",
    "    num_train_imgs refers to total number of training images that we wish to take.\"\"\"\n",
    "  num_test_imgs= int(num_train_imgs/10) ## taking only 1/10th number of train images for testing. \n",
    "  (xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n",
    "  xtrain = xtrain[: num_train_imgs] \n",
    "  xtest = xtest[:num_test_imgs] \n",
    "  ytrain = ytrain[: num_train_imgs]\n",
    "  ytest = ytest[:num_test_imgs]\n",
    "  xtrain, xtest = xtrain/255, xtest/255   # normalizing all values between 0 and 1.\n",
    "  # Let's start build a random neural network.\n",
    "\n",
    "  model = tf.keras.models.Sequential([   \n",
    "  tf.keras.layers.Flatten(input_shape=xtrain[0].shape),\n",
    "  tf.keras.layers.Dense(num_hidden_units, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(dropout),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "  ])\n",
    "  optimizer = tf.keras.optimizers.SGD(lr=learning_rate,\n",
    "  momentum=momentum,\n",
    "  nesterov=True)\n",
    "  model.compile(optimizer=optimizer,\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=['accuracy'])  ## taking accuracy as the evaluation metric.\n",
    "  \n",
    "  model.fit(xtrain, ytrain,\n",
    "  epochs=epochs,\n",
    "  batch_size=batch_size)\n",
    "  test_loss, test_acc = model.evaluate(xtest, ytest, verbose=2)\n",
    "  # print(\"test loss: \", test_loss)\n",
    "  print(\"test_acc: \", test_acc)\n",
    "  points.append((num_train_imgs, num_hidden_units, dropout, learning_rate,momentum,\n",
    "  epochs, batch_size, test_acc))\n",
    "  df_points=pd.DataFrame(points, columns=[\"num_train_imgs\", \"num_hidden_units\", \"dropout\", \"learning_rate\",\"momentum\",\n",
    "  \"epochs\", \"batch_size\", \"test_acc\"])\n",
    "\n",
    "  return df_points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYa4eNjHGJ-p"
   },
   "outputs": [],
   "source": [
    "#  define search space.\n",
    "## you can add/remove or edit these parameter values in the list.\n",
    "space={\"num_train_imgs\": [100,200] ,\n",
    "\"num_hidden_units\":[20,30],\n",
    "\"dropout\":[ 0.05],\n",
    "\"learning_rate\":[0.01, 0.03],\n",
    "\"momentum\":[ 0.2],\n",
    "\"epochs\":[5,10],\n",
    "\"batch_size\":[4]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z2l7Bkw1tAyt",
    "outputId": "7332f700-12b1-4e3b-fc9e-f4c16d3dc6a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 1ms/step - loss: 2.2992 - accuracy: 0.1200\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 0s 962us/step - loss: 2.0528 - accuracy: 0.3300\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 0s 954us/step - loss: 1.8615 - accuracy: 0.4100\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.6536 - accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4079 - accuracy: 0.7000\n",
      "1/1 - 0s - loss: 1.6530 - accuracy: 0.4000 - 88ms/epoch - 88ms/step\n",
      "test_acc:  0.4000000059604645\n",
      "num_train_imgs:  100 num_hidden_units:  20 dropout:  0.05 learning_rate:  0.01 momentum:  0.2 epochs:  5 batch_size:  4\n",
      "============ *********** ============ *********** ============ ***********\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2.2414 - accuracy: 0.2000\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2.0055 - accuracy: 0.3500\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.7745 - accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5643 - accuracy: 0.6500\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4133 - accuracy: 0.7300\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.2497 - accuracy: 0.7300\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.1171 - accuracy: 0.7500\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.0143 - accuracy: 0.7600\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 994us/step - loss: 0.9159 - accuracy: 0.8500\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.8194 - accuracy: 0.9000\n",
      "1/1 - 0s - loss: 1.2115 - accuracy: 0.6000 - 84ms/epoch - 84ms/step\n",
      "test_acc:  0.6000000238418579\n",
      "num_train_imgs:  100 num_hidden_units:  20 dropout:  0.05 learning_rate:  0.01 momentum:  0.2 epochs:  10 batch_size:  4\n",
      "============ *********** ============ *********** ============ ***********\n",
      "Epoch 1/5\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2.0911 - accuracy: 0.3100\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4034 - accuracy: 0.6600\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.9801 - accuracy: 0.8600\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7380 - accuracy: 0.8500\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5820 - accuracy: 0.8900\n",
      "1/1 - 0s - loss: 1.0226 - accuracy: 0.7000 - 347ms/epoch - 347ms/step\n",
      "test_acc:  0.699999988079071\n",
      "num_train_imgs:  100 num_hidden_units:  20 dropout:  0.05 learning_rate:  0.03 momentum:  0.2 epochs:  5 batch_size:  4\n",
      "============ *********** ============ *********** ============ ***********\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2.0702 - accuracy: 0.2800\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4965 - accuracy: 0.6100\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.0875 - accuracy: 0.7100\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7669 - accuracy: 0.8500\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5765 - accuracy: 0.9000\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4229 - accuracy: 0.9200\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.9600\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2803 - accuracy: 0.9300\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2433 - accuracy: 0.9600\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.9700\n",
      "1/1 - 0s - loss: 0.9201 - accuracy: 0.6000 - 86ms/epoch - 86ms/step\n",
      "test_acc:  0.6000000238418579\n",
      "num_train_imgs:  100 num_hidden_units:  20 dropout:  0.05 learning_rate:  0.03 momentum:  0.2 epochs:  10 batch_size:  4\n",
      "============ *********** ============ *********** ============ ***********\n",
      "Epoch 1/5\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2.3210 - accuracy: 0.0900\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 0s 966us/step - loss: 2.0662 - accuracy: 0.3300\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.7870 - accuracy: 0.5400\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 0s 991us/step - loss: 1.5561 - accuracy: 0.7100\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 0s 951us/step - loss: 1.3244 - accuracy: 0.7700\n",
      "1/1 - 0s - loss: 1.4858 - accuracy: 0.6000 - 84ms/epoch - 84ms/step\n",
      "test_acc:  0.6000000238418579\n",
      "num_train_imgs:  100 num_hidden_units:  30 dropout:  0.05 learning_rate:  0.01 momentum:  0.2 epochs:  5 batch_size:  4\n",
      "============ *********** ============ *********** ============ ***********\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2.3052 - accuracy: 0.1300\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.9911 - accuracy: 0.4700\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.7195 - accuracy: 0.6400\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4836 - accuracy: 0.6900\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.3021 - accuracy: 0.7200\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.1233 - accuracy: 0.7700\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.9785 - accuracy: 0.8000\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.8571 - accuracy: 0.8300\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7686 - accuracy: 0.8600\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.9400\n",
      "1/1 - 0s - loss: 1.3130 - accuracy: 0.7000 - 85ms/epoch - 85ms/step\n",
      "test_acc:  0.699999988079071\n",
      "num_train_imgs:  100 num_hidden_units:  30 dropout:  0.05 learning_rate:  0.01 momentum:  0.2 epochs:  10 batch_size:  4\n",
      "============ *********** ============ *********** ============ ***********\n",
      "Epoch 1/5\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2.0698 - accuracy: 0.2800\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.4218 - accuracy: 0.6900\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.0234 - accuracy: 0.7600\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6721 - accuracy: 0.8500\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.9300\n",
      "1/1 - 0s - loss: 0.9869 - accuracy: 0.7000 - 85ms/epoch - 85ms/step\n",
      "test_acc:  0.699999988079071\n",
      "num_train_imgs:  100 num_hidden_units:  30 dropout:  0.05 learning_rate:  0.03 momentum:  0.2 epochs:  5 batch_size:  4\n",
      "============ *********** ============ *********** ============ ***********\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 2.1475 - accuracy: 0.2600\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.5889 - accuracy: 0.5800\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 1.1323 - accuracy: 0.7400\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.8187 - accuracy: 0.8900\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5571 - accuracy: 0.9300\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.9400\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3256 - accuracy: 0.9600\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2576 - accuracy: 0.9700\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2133 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 1.0000\n",
      "1/1 - 0s - loss: 0.7992 - accuracy: 0.7000 - 85ms/epoch - 85ms/step\n",
      "test_acc:  0.699999988079071\n",
      "num_train_imgs:  100 num_hidden_units:  30 dropout:  0.05 learning_rate:  0.03 momentum:  0.2 epochs:  10 batch_size:  4\n",
      "============ *********** ============ *********** ============ ***********\n",
      "Epoch 1/5\n",
      "50/50 [==============================] - 0s 902us/step - loss: 2.1291 - accuracy: 0.3000\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 0s 895us/step - loss: 1.7705 - accuracy: 0.5200\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 0s 926us/step - loss: 1.4752 - accuracy: 0.6600\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 0s 915us/step - loss: 1.2103 - accuracy: 0.7550\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 0s 963us/step - loss: 0.9892 - accuracy: 0.8300\n",
      "1/1 - 0s - loss: 1.2349 - accuracy: 0.6500 - 85ms/epoch - 85ms/step\n",
      "test_acc:  0.6499999761581421\n",
      "num_train_imgs:  200 num_hidden_units:  20 dropout:  0.05 learning_rate:  0.01 momentum:  0.2 epochs:  5 batch_size:  4\n",
      "============ *********** ============ *********** ============ ***********\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 2.1808 - accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 1.7975 - accuracy: 0.5400\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 945us/step - loss: 1.4560 - accuracy: 0.6600\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 989us/step - loss: 1.1654 - accuracy: 0.7700\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 974us/step - loss: 0.9811 - accuracy: 0.8050\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.8337 - accuracy: 0.8300\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 981us/step - loss: 0.6881 - accuracy: 0.8300\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 907us/step - loss: 0.6118 - accuracy: 0.8550\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 906us/step - loss: 0.5424 - accuracy: 0.8800\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 927us/step - loss: 0.4782 - accuracy: 0.9000\n",
      "1/1 - 0s - loss: 0.9850 - accuracy: 0.7000 - 90ms/epoch - 90ms/step\n",
      "test_acc:  0.699999988079071\n",
      "num_train_imgs:  200 num_hidden_units:  20 dropout:  0.05 learning_rate:  0.01 momentum:  0.2 epochs:  10 batch_size:  4\n",
      "============ *********** ============ *********** ============ ***********\n",
      "Epoch 1/5\n",
      "50/50 [==============================] - 0s 900us/step - loss: 1.8519 - accuracy: 0.4400\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 0s 877us/step - loss: 1.0962 - accuracy: 0.7150\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 0s 888us/step - loss: 0.7437 - accuracy: 0.8200\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 0s 978us/step - loss: 0.5279 - accuracy: 0.8700\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.4157 - accuracy: 0.9000\n",
      "1/1 - 0s - loss: 0.8080 - accuracy: 0.8000 - 83ms/epoch - 83ms/step\n",
      "test_acc:  0.800000011920929\n",
      "num_train_imgs:  200 num_hidden_units:  20 dropout:  0.05 learning_rate:  0.03 momentum:  0.2 epochs:  5 batch_size:  4\n",
      "============ *********** ============ *********** ============ ***********\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 0s 927us/step - loss: 1.9166 - accuracy: 0.3900\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 1.0965 - accuracy: 0.7700\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 911us/step - loss: 0.7482 - accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.8650\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.9300\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3560 - accuracy: 0.9000\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.9400\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 958us/step - loss: 0.2096 - accuracy: 0.9750\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.9750\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 926us/step - loss: 0.1772 - accuracy: 0.9600\n",
      "1/1 - 0s - loss: 0.8731 - accuracy: 0.7000 - 82ms/epoch - 82ms/step\n",
      "test_acc:  0.699999988079071\n",
      "num_train_imgs:  200 num_hidden_units:  20 dropout:  0.05 learning_rate:  0.03 momentum:  0.2 epochs:  10 batch_size:  4\n",
      "============ *********** ============ *********** ============ ***********\n",
      "Epoch 1/5\n",
      "50/50 [==============================] - 0s 941us/step - loss: 2.1322 - accuracy: 0.3300\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 1.6100 - accuracy: 0.6250\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 0s 978us/step - loss: 1.1949 - accuracy: 0.7300\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 0s 906us/step - loss: 0.9428 - accuracy: 0.8100\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 0s 916us/step - loss: 0.7820 - accuracy: 0.8400\n",
      "1/1 - 0s - loss: 1.1338 - accuracy: 0.7500 - 165ms/epoch - 165ms/step\n",
      "test_acc:  0.75\n",
      "num_train_imgs:  200 num_hidden_units:  30 dropout:  0.05 learning_rate:  0.01 momentum:  0.2 epochs:  5 batch_size:  4\n",
      "============ *********** ============ *********** ============ ***********\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 0s 993us/step - loss: 2.1161 - accuracy: 0.3000\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 913us/step - loss: 1.6718 - accuracy: 0.6150\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 877us/step - loss: 1.3502 - accuracy: 0.7350\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 890us/step - loss: 1.1103 - accuracy: 0.8000\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 928us/step - loss: 0.8994 - accuracy: 0.8300\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 892us/step - loss: 0.7526 - accuracy: 0.8500\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 914us/step - loss: 0.6318 - accuracy: 0.8650\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5761 - accuracy: 0.8850\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 937us/step - loss: 0.5020 - accuracy: 0.8900\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 984us/step - loss: 0.4479 - accuracy: 0.9100\n",
      "1/1 - 0s - loss: 0.9659 - accuracy: 0.7000 - 92ms/epoch - 92ms/step\n",
      "test_acc:  0.699999988079071\n",
      "num_train_imgs:  200 num_hidden_units:  30 dropout:  0.05 learning_rate:  0.01 momentum:  0.2 epochs:  10 batch_size:  4\n",
      "============ *********** ============ *********** ============ ***********\n",
      "Epoch 1/5\n",
      "50/50 [==============================] - 0s 941us/step - loss: 1.8289 - accuracy: 0.3950\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 0s 935us/step - loss: 1.0083 - accuracy: 0.7900\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 0s 991us/step - loss: 0.6229 - accuracy: 0.8650\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 0s 859us/step - loss: 0.4576 - accuracy: 0.8850\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 0s 968us/step - loss: 0.3188 - accuracy: 0.9400\n",
      "1/1 - 0s - loss: 0.7787 - accuracy: 0.7000 - 97ms/epoch - 97ms/step\n",
      "test_acc:  0.699999988079071\n",
      "num_train_imgs:  200 num_hidden_units:  30 dropout:  0.05 learning_rate:  0.03 momentum:  0.2 epochs:  5 batch_size:  4\n",
      "============ *********** ============ *********** ============ ***********\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 0s 954us/step - loss: 1.8733 - accuracy: 0.3800\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 978us/step - loss: 0.9974 - accuracy: 0.7700\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 918us/step - loss: 0.6294 - accuracy: 0.8500\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 982us/step - loss: 0.4294 - accuracy: 0.8950\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.3048 - accuracy: 0.9550\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.2418 - accuracy: 0.9500\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 981us/step - loss: 0.1714 - accuracy: 0.9800\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 980us/step - loss: 0.1353 - accuracy: 0.9950\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1496 - accuracy: 0.9700\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0973 - accuracy: 0.9950\n",
      "1/1 - 0s - loss: 0.8160 - accuracy: 0.7500 - 87ms/epoch - 87ms/step\n",
      "test_acc:  0.75\n",
      "num_train_imgs:  200 num_hidden_units:  30 dropout:  0.05 learning_rate:  0.03 momentum:  0.2 epochs:  10 batch_size:  4\n",
      "============ *********** ============ *********** ============ ***********\n"
     ]
    }
   ],
   "source": [
    "# The greedy approach goes like this.\n",
    "# search for all possible combination of the search space and find the accuracy.\n",
    "# we can make use of for loops in a basic level.\n",
    "\n",
    "for m in space['num_train_imgs']:\n",
    "  for n in space['num_hidden_units']:\n",
    "    for p in space['dropout']:\n",
    "      for q in space['learning_rate']:\n",
    "        for w in space['momentum']:\n",
    "          for u in space[\"epochs\"]:\n",
    "            for v in space[\"batch_size\"]:\n",
    "              df=tune_mnist(num_train_imgs=m, num_hidden_units=n, dropout=p,learning_rate=q,momentum=w,epochs=u, batch_size=v)\n",
    "              print(\"num_train_imgs: \", m, \"num_hidden_units: \", n,\n",
    "              \"dropout: \", p, \"learning_rate: \", q, \"momentum: \", w,\n",
    "              \"epochs: \", u, \"batch_size: \", v)\n",
    "              print(\"============ *********** ============ *********** ============ ***********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUDPQrKrtA0_",
    "outputId": "74877836-65ef-4af0-bc4d-6d20d973a52d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value of column test_accuracy   and its corresponding row values:\n",
      " num_train_imgs      200.00\n",
      "num_hidden_units     20.00\n",
      "dropout               0.05\n",
      "learning_rate         0.03\n",
      "momentum              0.20\n",
      "epochs                5.00\n",
      "batch_size            4.00\n",
      "test_acc              0.80\n",
      "Name: 10, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Inorder to find the best parameters at a glance and associated values.\n",
    "max_val = df.loc[df['test_acc'].idxmax()]\n",
    "print(\"Maximum value of column test_accuracy \" , \" and its corresponding row values:\\n\", max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvLYwnENunkP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDyZDEV_tA3t"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
